{"id":"1","text":"<h2>Consent Form</h2><p>You are being asked to participate in a research study being conducted by Carnegie Mellon University [study number: STUDY2025_00000225]</p><p>The purpose of this research study is to create a system that evaluates how AI assistants behave in ethically challenging situations. You will be given 10 different scenarios in which a user's behavior presents an AI assistant with a moral dilemma and asked to evaluate each of them on dimensions such as realism, feasibility, conflict, or ambiguity. You will also rate the overall quality of each scenario and may be asked to write a short justification of your ratings.</p><p><strong>Warning: Some of the scenarios you will be asked to evaluate may deal with sensitive subjects such as discrimination, interpersonal conflict, and mental health.</strong></p><p>Your Prolific ID will be used to confirm your study participation and distribute payment, but we will not store your Prolific ID with your survey responses. The anonymized data will be securely stored locally and on Google Drive for several months but will not be made available to other researchers (except for high-level summary statistics and individual instances of anonymized responses).</p><p>Please note that the research may include one or more attention checks which are designed to detect inattentive behavior of participants. If you are found to have failed attention checks, there will be no compensation provided. This negatively impacts the research and the data will be discarded.</p><p>Please contact andyliu@andrew.cmu.edu with any further questions about the study.</p>","schema": "pure_display", "choices": [""]}
{"id":"2","text":"If you give your consent please click \"I agree\" below.","schema": "radio", "choices": ["I agree", "I do not agree"], "label_requirement": {"right_label":["I agree"]}}
{"id":"3","text":"Please enter your Prolific ID.","schema": "text", "label_requirement": {"required":true}}